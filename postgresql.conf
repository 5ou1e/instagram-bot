log_statement = 'none'
logging_collector = off
listen_addresses = '*'
max_connections = 100
work_mem = 256MB  # Для улучшения работы с большими объемами данных
hash_mem_multiplier = 2.0 # контролирует, сколько памяти можно дополнительно выделить для операций хэширования
maintenance_work_mem = 8GB  # Для ускорения операций обслуживания
checkpoint_completion_target = 0.9  # Распределяем нагрузку на диск
effective_cache_size = 32GB  # Учитывая 128 GB RAM, задаем большой размер кэша
max_wal_size = 20GB  # Увеличим размер WAL для снижения нагрузок
min_wal_size = 2GB  # Увеличиваем минимальный размер WAL
wal_buffers = 1024MB
random_page_cost = 1.1  # Для SSD, уменьшаем стоимость случайных операций чтения
max_parallel_workers_per_gather = 16  # Увеличиваем для многозадачности на многоядерных процессорах
vacuum_cost_limit = 5000  # Увеличиваем лимит для ускорения VACUUM
max_worker_processes = 32  # Увеличим количество фоновых процессов для использования всех ядер
max_parallel_workers = 32  # Увеличиваем число рабочих процессов для параллельных запросов
max_parallel_workers_per_gather = 16  # Разрешаем больше параллельных рабочих для Gather
max_parallel_maintenance_workers = 8 # Количество параллельных процессов, которые участвуют в создании индекса
shared_buffers = 16GB # определяет, сколько памяти PostgreSQL использует для своих операций
autovacuum_analyze_scale_factor = 0      # Обновлять статистику, когда % строк изменится
autovacuum_analyze_threshold = 10000         # Минимум строк должно быть изменено для анализа
autovacuum_vacuum_scale_factor = 0.1    # Вакуум будет запускаться, когда % строк изменится
autovacuum_vacuum_threshold = 10000      # Минимум 1000 строк должно быть изменено для вакуума
autovacuum_naptime = 60s   # Период времени между проверками на необходимость запуска autovacuum